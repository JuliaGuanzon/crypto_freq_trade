{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce62c2b-0da8-4e12-a149-33e0effef241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import mplfinance as mpl\n",
    "import mplfinance as mpf\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "\n",
    "import arrow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import quandl\n",
    "\n",
    "from model import build_model\n",
    "from read_tickers import read_stocks\n",
    "from send_email import send_email\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4d4b4e-0671-457d-8c5f-2a68ba934ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets stock data from quandl in the form of a np array\n",
    "def get_stock_data(stock_ticker, num_days_back, minimum_days):\n",
    "    print(\"GETTING STOCK DATA\")\n",
    "\n",
    "    end_date = arrow.now().format(\"YYYY-MM-DD\")\n",
    "    start_date = arrow.now()\n",
    "    start_date = start_date.replace(days=(num_days_back*-1)).format(\"YYYY-MM-DD\")\n",
    "\n",
    "    quandl_api_key = \"DqEaArDZQP8SfgHTd_Ko\"\n",
    "    quandl.ApiConfig.api_key = quandl_api_key\n",
    "\n",
    "    source = \"WIKI/\" + stock_ticker\n",
    "\n",
    "    print(\"    Retrieving data from quandl API...\")\n",
    "    data = quandl.get(source, start_date=str(start_date), end_date=str(end_date))\n",
    "    data = data[[\"Open\", \"High\", \"Low\", \"Volume\", \"Close\"]].as_matrix()\n",
    "\n",
    "    if len(data) < minimum_days:\n",
    "        raise quandl.errors.quandl_error.NotFoundError\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9648f-c89e-45ed-8230-6edf17557dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_timestep(timestep, reference_list):\n",
    "    reference_price = timestep[0][0]\n",
    "    reference_list.append(reference_price)\n",
    "\n",
    "    temp_volume = np.copy(timestep[:, 3])\n",
    "    reference_volume = np.copy(timestep[0, 3])\n",
    "\n",
    "    timestep = (timestep / reference_price) - 1\n",
    "    timestep[:, 3] = (temp_volume / reference_volume) - 1\n",
    "    return timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8acbe58-5ac0-4d81-8dfb-e442579d97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take data and split into timeseries so that we can train the model\n",
    "def load_data(stock_data, num_timesteps, target_len, train_percent=.75):\n",
    "\n",
    "    # iterate so that we can also capture a sequence for a target\n",
    "    combined_length = num_timesteps + target_len\n",
    "\n",
    "    print(\"SPLITTING INTO TIMESERIES\")\n",
    "\n",
    "    # segment the data into timeseries (these will be overlapping)\n",
    "    result = []\n",
    "    for index in range(len(stock_data) - combined_length):\n",
    "        time_series = stock_data[index: index + combined_length]\n",
    "        result.append(time_series[:])\n",
    "\n",
    "    result = np.asarray(result)\n",
    "\n",
    "    # normalize\n",
    "    reference_points = [] #for de-normalizing outside of the function\n",
    "    for i in range(0, len(result)):\n",
    "        result[i] = normalize_timestep(result[i], reference_points)\n",
    "\n",
    "\n",
    "    # train test split\n",
    "    row = round(train_percent * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    test = result[int(row):, :]\n",
    "\n",
    "    split_index = len(train[0]) - target_len\n",
    "    x_train = train[:, :split_index]\n",
    "    y_train = train[:, split_index:, -1]\n",
    "\n",
    "    x_test = test[:, :split_index]\n",
    "    y_test = test[:, split_index:, -1]\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test, reference_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579e81c-6ca4-45fd-83c2-a270edcee59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(stock_name, days_back, num_timesteps, target_len, minimum_days=500):\n",
    "    stock_name = stock_name\n",
    "    stock_data = get_stock_data(stock_name, days_back, minimum_days)\n",
    "\n",
    "    X_train, y_train, X_test, y_test, ref = load_data(stock_data, num_timesteps, target_len=target_len, train_percent=.9)\n",
    "\n",
    "    # store recent data so that we can get a live prediction\n",
    "    recent_reference = []\n",
    "    recent_data = stock_data[-num_timesteps:]\n",
    "    recent_data = normalize_timestep(recent_data, recent_reference)\n",
    "\n",
    "    print(\"    X_train\", X_train.shape)\n",
    "    print(\"    y_train\", y_train.shape)\n",
    "    print(\"    X_test\", X_test.shape)\n",
    "    print(\"    y_test\", y_test.shape)\n",
    "\n",
    "    # setup model\n",
    "    print(\"TRAINING\")\n",
    "    model = build_model([5, num_timesteps, target_len])\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=512,\n",
    "        epochs=1,\n",
    "        validation_split=0.1,\n",
    "        verbose=2)\n",
    "\n",
    "    #train the model\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=100)\n",
    "    print('Train Score: %.2f MSE (%.2f RMSE) (%.2f)' % (trainScore[0], math.sqrt(trainScore[0]), trainScore[1]))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=100)\n",
    "    print('Test Score: %.2f MSE (%.2f RMSE) (%.2f)' % (testScore[0], math.sqrt(testScore[0]), testScore[1]))\n",
    "\n",
    "    #make predictions\n",
    "    print(\"PREDICTING\")\n",
    "    p = model.predict(X_test)\n",
    "    recent_data = [recent_data] # One-sample predictions need list wrapper. Argument must be 3d.\n",
    "    recent_data = np.asarray(recent_data)\n",
    "    future = model.predict([recent_data])\n",
    "\n",
    "    # document results in file\n",
    "    print(\"WRITING TO LOG\")\n",
    "    file = open(\"log.txt\", \"w\")\n",
    "    for i in range(0, len(X_train)):\n",
    "        for s in range(0, num_timesteps):\n",
    "            file.write(str(X_train[i][s]) + \"\\n\")\n",
    "        file.write(\"Target: \" + str(y_train[i]) + \"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    for i in range(0, len(X_test)):\n",
    "        for s in range(0, num_timesteps):\n",
    "            file.write(str(X_test[i][s]) + \"\\n\")\n",
    "        file.write(\"Target: \" + str(y_test[i]) + \"\\n\")\n",
    "        file.write(\"Prediction: \" + str(p[i]) + \"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    # de-normalize\n",
    "    print(\"DENORMALIZING\")\n",
    "    for i in range(0, len(p)):\n",
    "        p[i] = (p[i] + 1) * ref[round(.9 * len(ref) + i)]\n",
    "        y_test[i] = (y_test[i] + 1) * ref[round(.9 * len(ref) + i)]\n",
    "\n",
    "    future[0] = (future[0] + 1) * recent_reference[0]\n",
    "    recent_data[0] = (recent_data[0] + 1) * recent_reference[0]\n",
    "\n",
    "    # plot historical predictions\n",
    "    print(\"PLOTTING\")\n",
    "    for i in range(0, len(p)):\n",
    "        if i % (target_len*2) == 0:\n",
    "            plot_index = i #for filling plot indexes\n",
    "            plot_indexes = []\n",
    "            plot_values = p[i]\n",
    "            for j in range(0, target_len):\n",
    "                plot_indexes.append(plot_index)\n",
    "                plot_index += 1\n",
    "            plt.plot(plot_indexes, plot_values, color=\"red\")\n",
    "\n",
    "    # plot historical actual\n",
    "    plt.plot(y_test[:, 0], color='blue', label='Actual') # actual stock price history\n",
    "\n",
    "    # plot recent prices\n",
    "    plot_indexes = [len(y_test) - 1]\n",
    "    plot_values = [y_test[-1, 0]]\n",
    "    plot_index = None\n",
    "    for i in range(0, len(recent_data[0])):\n",
    "        plot_values.append(recent_data[0][i][0])\n",
    "        plot_index = len(y_test) + i\n",
    "        plot_indexes.append(len(y_test)+i)\n",
    "    plt.plot(plot_indexes, plot_values, color='blue')\n",
    "\n",
    "    # plot future predictions\n",
    "    plot_indexes = [plot_index]\n",
    "    plot_values = [recent_data[0][-1][0]]\n",
    "    for i in range(0, len(future[0])):\n",
    "        plot_index += 1\n",
    "        plot_values.append(future[0][i])\n",
    "        plot_indexes.append(plot_index)\n",
    "    plt.plot(plot_indexes, plot_values, color=\"red\", label=\"Prediction\")\n",
    "\n",
    "    #show/save plot\n",
    "    print(\"SENDING EMAILS\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(stock_name + \" Price Predictions\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price ($)\")\n",
    "    filename = stock_name + \"_\" + str(arrow.utcnow().format(\"YYYY-MM-DD\") + \"_\" + str(days_back))\n",
    "    plt.savefig(\"graphs/\" + filename)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    send_email(filename)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc338db9-de95-4d89-a417-b30bf1a4c1d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_stocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1fe870eb46bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# MAIN()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtickers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_stocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqlisted.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnum_days_back\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3700\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_stocks' is not defined"
     ]
    }
   ],
   "source": [
    "# MAIN()\n",
    "\n",
    "tickers = read_stocks(\"ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqlisted.txt\")\n",
    "num_days_back = 3700\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(\"Ticker:\" + str(ticker))\n",
    "\n",
    "    try:\n",
    "        isDone = generate_graph(ticker, num_days_back, 100, 30)\n",
    "    except quandl.errors.quandl_error.NotFoundError:\n",
    "        continue\n",
    "\n",
    "    # generate_graph(ticker, 300, 20, 10) #FOR TESTING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
